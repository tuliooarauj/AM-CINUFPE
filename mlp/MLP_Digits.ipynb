{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2Ayi00KQngCv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glo64_l2-4   | CV macro-F1 = 0.976 ± 0.009\n",
            "glo64_l2-3   | CV macro-F1 = 0.976 ± 0.008\n",
            "norm64_l2-4  | CV macro-F1 = 0.977 ± 0.008\n",
            "heDeep_l2-4  | CV macro-F1 = 0.973 ± 0.013\n",
            "heDeep_l2-3  | CV macro-F1 = 0.976 ± 0.013\n",
            "reluWide_l2-2 | CV macro-F1 = 0.975 ± 0.007\n",
            "tanhDeep_l2-5 | CV macro-F1 = 0.974 ± 0.007\n",
            "reluSmall_l2-3 | CV macro-F1 = 0.980 ± 0.011\n",
            "logNorm_l2-2 | CV macro-F1 = 0.976 ± 0.003\n",
            "reluDeep_l2-5 | CV macro-F1 = 0.973 ± 0.010\n",
            "tanhCompact_l2-3 | CV macro-F1 = 0.976 ± 0.007\n",
            "\n",
            ">> Selecionado: reluSmall_l2-3 {'layers': (64,), 'alpha': 0.001, 'weight_init': 'he_uniform', 'activation': 'relu'}\n",
            "\n",
            ">> TESTE | acc = 0.950 | macro-F1 = 0.949\n",
            "\n",
            "Resumo completo:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config</th>\n",
              "      <th>layers</th>\n",
              "      <th>alpha</th>\n",
              "      <th>init</th>\n",
              "      <th>acc_mean</th>\n",
              "      <th>acc_std</th>\n",
              "      <th>f1_mean</th>\n",
              "      <th>f1_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>reluSmall_l2-3</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.979822</td>\n",
              "      <td>0.010869</td>\n",
              "      <td>0.979824</td>\n",
              "      <td>0.010874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>norm64_l2-4</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.977033</td>\n",
              "      <td>0.008426</td>\n",
              "      <td>0.977016</td>\n",
              "      <td>0.008493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>glo64_l2-4</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.976345</td>\n",
              "      <td>0.008904</td>\n",
              "      <td>0.976339</td>\n",
              "      <td>0.008876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>heDeep_l2-3</td>\n",
              "      <td>(128, 64)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.976348</td>\n",
              "      <td>0.012700</td>\n",
              "      <td>0.976321</td>\n",
              "      <td>0.012725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>tanhCompact_l2-3</td>\n",
              "      <td>(64, 32)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.976338</td>\n",
              "      <td>0.007440</td>\n",
              "      <td>0.976282</td>\n",
              "      <td>0.007396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>glo64_l2-3</td>\n",
              "      <td>(64,)</td>\n",
              "      <td>0.00100</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.976338</td>\n",
              "      <td>0.008070</td>\n",
              "      <td>0.976257</td>\n",
              "      <td>0.008058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>logNorm_l2-2</td>\n",
              "      <td>(128, 64)</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>normal</td>\n",
              "      <td>0.975648</td>\n",
              "      <td>0.003073</td>\n",
              "      <td>0.975620</td>\n",
              "      <td>0.003031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>reluWide_l2-2</td>\n",
              "      <td>(256, 256)</td>\n",
              "      <td>0.01000</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.974952</td>\n",
              "      <td>0.006741</td>\n",
              "      <td>0.974978</td>\n",
              "      <td>0.006665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tanhDeep_l2-5</td>\n",
              "      <td>(128, 64, 32)</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>glorot</td>\n",
              "      <td>0.974255</td>\n",
              "      <td>0.007161</td>\n",
              "      <td>0.974228</td>\n",
              "      <td>0.007118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>heDeep_l2-4</td>\n",
              "      <td>(128, 64)</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.973543</td>\n",
              "      <td>0.013347</td>\n",
              "      <td>0.973461</td>\n",
              "      <td>0.013315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>reluDeep_l2-5</td>\n",
              "      <td>(256, 128, 64)</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>he_uniform</td>\n",
              "      <td>0.972868</td>\n",
              "      <td>0.009915</td>\n",
              "      <td>0.972730</td>\n",
              "      <td>0.009972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              config          layers    alpha        init  acc_mean   acc_std  \\\n",
              "7     reluSmall_l2-3           (64,)  0.00100  he_uniform  0.979822  0.010869   \n",
              "2        norm64_l2-4           (64,)  0.00010      normal  0.977033  0.008426   \n",
              "0         glo64_l2-4           (64,)  0.00010      glorot  0.976345  0.008904   \n",
              "4        heDeep_l2-3       (128, 64)  0.00100  he_uniform  0.976348  0.012700   \n",
              "10  tanhCompact_l2-3        (64, 32)  0.00100      glorot  0.976338  0.007440   \n",
              "1         glo64_l2-3           (64,)  0.00100      glorot  0.976338  0.008070   \n",
              "8       logNorm_l2-2       (128, 64)  0.01000      normal  0.975648  0.003073   \n",
              "5      reluWide_l2-2      (256, 256)  0.01000  he_uniform  0.974952  0.006741   \n",
              "6      tanhDeep_l2-5   (128, 64, 32)  0.00001      glorot  0.974255  0.007161   \n",
              "3        heDeep_l2-4       (128, 64)  0.00010  he_uniform  0.973543  0.013347   \n",
              "9      reluDeep_l2-5  (256, 128, 64)  0.00001  he_uniform  0.972868  0.009915   \n",
              "\n",
              "     f1_mean    f1_std  \n",
              "7   0.979824  0.010874  \n",
              "2   0.977016  0.008493  \n",
              "0   0.976339  0.008876  \n",
              "4   0.976321  0.012725  \n",
              "10  0.976282  0.007396  \n",
              "1   0.976257  0.008058  \n",
              "8   0.975620  0.003031  \n",
              "5   0.974978  0.006665  \n",
              "6   0.974228  0.007118  \n",
              "3   0.973461  0.013315  \n",
              "9   0.972730  0.009972  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --------------------------------------------------\n",
        "# 0. Pacotes\n",
        "# --------------------------------------------------\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import (train_test_split,\n",
        "                                     StratifiedKFold,\n",
        "                                     cross_validate)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (accuracy_score,\n",
        "                             f1_score,\n",
        "                             make_scorer)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Wrapper: MLP com escolha de inicialização\n",
        "# --------------------------------------------------\n",
        "class InitMLP(MLPClassifier):\n",
        "    \"\"\"\n",
        "    MLPClassifier com escolha da estratégia de inicialização:\n",
        "    'glorot' (padrão), 'normal' ou 'he_uniform'.\n",
        "    \"\"\"\n",
        "    def __init__(self, *,              # força kwargs-only\n",
        "                 weight_init=\"glorot\",  # novo parâmetro\n",
        "                 **kwargs):             # passa o resto para o MLP original\n",
        "        super().__init__(**kwargs)\n",
        "        self.weight_init = weight_init\n",
        "\n",
        "    # --- substitui os pesos depois da _initialize do pai ---\n",
        "    def _initialize(self, y, layer_units, dtype):\n",
        "        super()._initialize(y, layer_units, dtype)\n",
        "        rng = self._random_state\n",
        "        for i, (fan_in, fan_out) in enumerate(zip(layer_units[:-1],\n",
        "                                                  layer_units[1:])):\n",
        "            shape = (fan_in, fan_out)\n",
        "            if self.weight_init == \"normal\":\n",
        "                scale = 1. / np.sqrt(fan_in)\n",
        "                self.coefs_[i] = rng.normal(0.0, scale, size=shape)\n",
        "            elif self.weight_init == \"he_uniform\":\n",
        "                limit = np.sqrt(6. / fan_in)\n",
        "                self.coefs_[i] = rng.uniform(-limit, limit, size=shape)\n",
        "            # ‘glorot’ já foi gerado pelo método do pai\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Dados\n",
        "# --------------------------------------------------\n",
        "X, y = load_digits(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. Configurações (arquitetura, L2, inicialização)\n",
        "# --------------------------------------------------\n",
        "configs = {\n",
        "    #  nome        layers                   alpha       init\n",
        "    \"glo64_l2-4\": dict(layers=(64,),       alpha=1e-4, weight_init=\"glorot\"),\n",
        "    \"glo64_l2-3\": dict(layers=(64,),       alpha=1e-3, weight_init=\"glorot\"),\n",
        "    \"norm64_l2-4\":dict(layers=(64,),       alpha=1e-4, weight_init=\"normal\"),\n",
        "    \"heDeep_l2-4\":dict(layers=(128, 64),   alpha=1e-4, weight_init=\"he_uniform\"),\n",
        "    \"heDeep_l2-3\":dict(layers=(128, 64),   alpha=1e-3, weight_init=\"he_uniform\"),\n",
        "    ## ... adicione mais 5 ou mais combinacoes ...\n",
        "\n",
        "    \"reluWide_l2-2\": dict(layers=(256, 256),\n",
        "                          alpha=1e-2,\n",
        "                          weight_init=\"he_uniform\",\n",
        "                          activation=\"relu\"),\n",
        "\n",
        "    \"tanhDeep_l2-5\": dict(layers=(128, 64, 32),\n",
        "                          alpha=1e-5,\n",
        "                          weight_init=\"glorot\",\n",
        "                          activation=\"tanh\"),\n",
        "\n",
        "    \"reluSmall_l2-3\": dict(layers=(64,),\n",
        "                           alpha=1e-3,\n",
        "                           weight_init=\"he_uniform\",\n",
        "                           activation=\"relu\"),\n",
        "\n",
        "    \"logNorm_l2-2\": dict(layers=(128, 64),\n",
        "                         alpha=1e-2,\n",
        "                         weight_init=\"normal\",\n",
        "                         activation=\"logistic\"),\n",
        "\n",
        "    \"reluDeep_l2-5\": dict(layers=(256, 128, 64),\n",
        "                          alpha=1e-5,\n",
        "                          weight_init=\"he_uniform\",\n",
        "                          activation=\"relu\"),\n",
        "\n",
        "    \"tanhCompact_l2-3\": dict(layers=(64, 32),\n",
        "                             alpha=1e-3,\n",
        "                             weight_init=\"glorot\",\n",
        "                             activation=\"tanh\")\n",
        "}\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. Validação cruzada no treino\n",
        "# --------------------------------------------------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\"acc\": \"accuracy\",\n",
        "           \"f1\":  make_scorer(f1_score, average=\"macro\")}\n",
        "\n",
        "rows = []\n",
        "for name, p in configs.items():\n",
        "    clf = InitMLP(\n",
        "        hidden_layer_sizes=p[\"layers\"],\n",
        "        alpha=p[\"alpha\"],\n",
        "        weight_init=p[\"weight_init\"],\n",
        "        max_iter=200,\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=5,\n",
        "        learning_rate_init=1e-3,\n",
        "        solver=\"adam\",\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "\n",
        "    pipe = Pipeline([(\"scale\", StandardScaler()),\n",
        "                     (\"clf\",   clf)])\n",
        "\n",
        "    res = cross_validate(pipe, X_train, y_train,\n",
        "                         cv=cv, scoring=scoring,\n",
        "                         return_train_score=False)\n",
        "\n",
        "    rows.append({\n",
        "        \"config\":   name,\n",
        "        \"layers\":   p[\"layers\"],\n",
        "        \"alpha\":    p[\"alpha\"],\n",
        "        \"init\":     p[\"weight_init\"],\n",
        "        \"f1_mean\":  res[\"test_f1\"].mean(),\n",
        "        \"f1_std\":   res[\"test_f1\"].std(),\n",
        "        \"acc_mean\": res[\"test_acc\"].mean(),\n",
        "        \"acc_std\":  res[\"test_acc\"].std(),\n",
        "    })\n",
        "\n",
        "    print(f\"{name:12s} | CV macro-F1 = \"\n",
        "          f\"{res['test_f1'].mean():.3f} ± {res['test_f1'].std():.3f}\")\n",
        "\n",
        "summary = (pd.DataFrame(rows)\n",
        "              .sort_values(\"f1_mean\", ascending=False))\n",
        "\n",
        "best_conf  = summary.iloc[0]\n",
        "best_name  = best_conf[\"config\"]\n",
        "best_param = configs[best_name]\n",
        "print(\"\\n>> Selecionado:\", best_name, dict(best_param))\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5. Re-treino em todo o treino + teste final\n",
        "# --------------------------------------------------\n",
        "best_clf = InitMLP(\n",
        "    hidden_layer_sizes=best_param[\"layers\"],\n",
        "    alpha=best_param[\"alpha\"],\n",
        "    weight_init=best_param[\"weight_init\"],\n",
        "    max_iter=200,\n",
        "    early_stopping=True,\n",
        "    n_iter_no_change=5,\n",
        "    learning_rate_init=1e-3,\n",
        "    solver=\"adam\",\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "best_pipe = Pipeline([(\"scale\", StandardScaler()),\n",
        "                      (\"clf\",   best_clf)])\n",
        "best_pipe.fit(X_train, y_train)\n",
        "\n",
        "y_pred   = best_pipe.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "test_f1  = f1_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "print(f\"\\n>> TESTE | acc = {test_acc:.3f} | macro-F1 = {test_f1:.3f}\")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6. Tabela resumo (para o relatório)\n",
        "# --------------------------------------------------\n",
        "print(\"\\nResumo completo:\")\n",
        "display(summary[[\"config\", \"layers\", \"alpha\", \"init\",\n",
        "                 \"acc_mean\", \"acc_std\", \"f1_mean\", \"f1_std\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Relatório\n",
        "\n",
        "\n",
        "### 1. Melhor configuração e justificativa\n",
        "A melhor configuração foi “reluSmall_l2-3”, com arquitetura (64,), regularização alpha=0.001, inicialização he_uniform e ativação ReLU. Essa combinação apresentou o maior valor médio de macro-F1 (0.979) na validação cruzada e manteve desempenho consistente no teste (acc = 0.950, macro-F1 = 0.949). O resultado demonstra que uma rede simples, bem regularizada e com inicialização adequada à ReLU pode superar arquiteturas mais profundas, pois evita sobreajuste e converge de forma mais estável.\n",
        "\n",
        "### 2. Diferença entre CV e Teste — Overfitting\n",
        "A diferença entre o macro-F1 médio da validação cruzada (0.979) e o valor obtido no teste (0.949) foi pequena (~0.03), o que indica baixo overfitting. As redes mais profundas, como “heDeep_l2-5” e “reluDeep_l2-5”, apresentaram resultados similares na validação, mas tendem a maior variância e custo computacional. A arquitetura mais simples manteve um equilíbrio ideal entre viés e variância.\n",
        "\n",
        "### 3. Impacto da ativação e da inicialização\n",
        "As redes com ReLU e inicialização He-uniform mostraram desempenho consistentemente superior às combinações com tanh e normal. A ReLU facilita o aprendizado em camadas intermediárias sem saturação de gradientes, enquanto a inicialização He mantém escalas de ativação apropriadas. Configurações com glorot e tanh apresentaram bom desempenho, mas menor estabilidade entre folds.\n",
        "\n",
        "### 4. Sugestões de melhoria futura\n",
        "- (a) Avaliar o uso de batch normalization para acelerar o treino e estabilizar gradientes em redes maiores;\n",
        "- (b) Explorar dropout ou valores ligeiramente maiores de alpha (ex.: 5e-3) para melhorar a generalização;"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
